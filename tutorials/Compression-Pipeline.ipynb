{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "DAEo_wyhLlHs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "===============================\\\n",
    "   Compression Pipeline\\\n",
    "==============================="
   ],
   "metadata": {
    "collapsed": false,
    "id": "5imcpcgZLlHt"
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "!pip install sconce -q"
   ],
   "metadata": {
    "collapsed": false,
    "id": "N2UNb0RyLlHu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sconce --quiet"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o8dmwh_LvSZ",
    "outputId": "ac78edfe-d23c-4991-bed4-9645199f2096"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m83.1/83.1 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.4/66.4 kB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.2/61.2 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.1/10.1 MB\u001B[0m \u001B[31m37.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.0/143.0 kB\u001B[0m \u001B[31m18.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m87.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m158.3/158.3 kB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.0/26.0 MB\u001B[0m \u001B[31m20.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m42.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m22.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.8/4.8 MB\u001B[0m \u001B[31m74.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m295.0/295.0 kB\u001B[0m \u001B[31m34.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.5/61.5 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.3/114.3 kB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m808.4/808.4 kB\u001B[0m \u001B[31m58.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.4/139.4 kB\u001B[0m \u001B[31m19.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m81.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.7/84.7 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.0/66.0 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.9/105.9 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m378.6/378.6 kB\u001B[0m \u001B[31m37.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.2/9.2 MB\u001B[0m \u001B[31m57.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.9/58.9 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m153.1/153.1 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Installing backend dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.6/11.6 MB\u001B[0m \u001B[31m54.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.0/48.0 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m256.6/256.6 kB\u001B[0m \u001B[31m31.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m68.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.2/18.2 MB\u001B[0m \u001B[31m57.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m40.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m36.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.8/209.8 MB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.5/20.5 MB\u001B[0m \u001B[31m32.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.3/12.3 MB\u001B[0m \u001B[31m36.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.0/59.0 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m36.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.5/61.5 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m385.1/385.1 kB\u001B[0m \u001B[31m35.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m283.6/283.6 kB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.6/62.6 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.1/53.1 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m325.1/325.1 kB\u001B[0m \u001B[31m32.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m123.4/123.4 kB\u001B[0m \u001B[31m15.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.5/93.5 kB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m773.9/773.9 kB\u001B[0m \u001B[31m37.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m33.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m40.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m109.0/109.0 kB\u001B[0m \u001B[31m15.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m34.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m34.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.1/121.1 kB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m37.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m427.7/427.7 kB\u001B[0m \u001B[31m36.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.0/85.0 kB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.9/7.9 MB\u001B[0m \u001B[31m30.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m341.8/341.8 kB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.3/102.3 kB\u001B[0m \u001B[31m14.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.3/57.3 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m25.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for lit (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires fastapi, which is not installed.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.26.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.17.2 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.0.6 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.3 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.3.2, but you have tornado 6.3.3 which is incompatible.\n",
      "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\n",
      "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xEDfNQnMIW9H",
    "ExecuteTime": {
     "end_time": "2023-12-01T07:32:53.170470032Z",
     "start_time": "2023-12-01T07:32:50.766056935Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.optim as optim\n",
    "\n",
    "assert torch.cuda.is_available(), \\\n",
    "\"The current runtime does not have CUDA support.\" \\\n",
    "\"Please go to menu bar (Runtime - Change runtime type) and select GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the Pre-Trained Model Weights"
   ],
   "metadata": {
    "id": "umyrKmgdEHQf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "model_path = \"drive/MyDrive/Efficientml/Efficientml.ai/vgg.cifar.pretrained.pth\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YI-g2PwnGf_s",
    "outputId": "2d6b306b-61c6-4d7f-a7b6-a09418dca75e"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class VGG(nn.Module):\n",
    "  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    in_channels = 3\n",
    "    for x in self.ARCH:\n",
    "      if x != 'M':\n",
    "        # conv-bn-relu\n",
    "        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
    "        add(\"bn\", nn.BatchNorm2d(x))\n",
    "        add(\"relu\", nn.ReLU(True))\n",
    "        in_channels = x\n",
    "      else:\n",
    "        # maxpool\n",
    "        add(\"pool\", nn.MaxPool2d(2))\n",
    "\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n",
    "    x = self.backbone(x)\n",
    "\n",
    "    # avgpool: [N, 512, 2, 2] => [N, 512]\n",
    "    x = x.mean([2, 3])\n",
    "\n",
    "    # classifier: [N, 512] => [N, 10]\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "#load the pretrained model\n",
    "\n",
    "model = VGG().cuda()\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8_S-wtTEGKu",
    "outputId": "f1877b9c-d994-4f4e-f0d1-2dd4cdc424fd",
    "ExecuteTime": {
     "end_time": "2023-12-01T07:32:56.646268058Z",
     "start_time": "2023-12-01T07:32:55.606697470Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup the Dataset"
   ],
   "metadata": {
    "id": "o020nzh1Ea3s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nozAsRWpNfa8",
    "outputId": "976c03ce-936e-4fcd-a15f-91efaba620d4",
    "ExecuteTime": {
     "end_time": "2023-12-01T07:33:50.919090166Z",
     "start_time": "2023-12-01T07:33:37.768089911Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 170498071/170498071 [00:02<00:00, 83361571.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/cifar10/cifar-10-python.tar.gz to data/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        RandomCrop(image_size, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "\n",
    "    dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms[split],\n",
    "    )\n",
    "\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=512,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "sconce Configurations"
   ],
   "metadata": {
    "id": "ByJy8c5NCxD3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YuCi_bPhNrMn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba23426c-7104-4fe4-830f-8a12eb94618b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sconce import sconce\n",
    "import copy\n",
    "\n",
    "\n",
    "sconces = sconce()\n",
    "sconces.model= copy.deepcopy(model)\n",
    "sconces.criterion = nn.CrossEntropyLoss() # Loss\n",
    "sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "sconces.dataloader = dataloader\n",
    "sconces.epochs = 1 #Number of time we iterate over the data\n",
    "sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sconces.experiment_name = \"vgg-gmp\"\n",
    "sconces.prune_mode = \"GMP\" # Supports Automated Pruning Ratio Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and Validated the Model on the given dataset"
   ],
   "metadata": {
    "id": "pTSAWI8REuFZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "sconces.train()\n",
    "# Evaludate the model\n",
    "sconces.evaluate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYNkCi7tC6Cl",
    "outputId": "a52b09d6-01f7-4465-efed-d125ed16b94f"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 92.90581\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "92.90581162324649"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Magic Happens here: Compress the model(GMP pruning is set as the prune mode[sconces.prune_mode] above)"
   ],
   "metadata": {
    "id": "RcOCi-1eFub4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sconces.compress()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1_dew86NADc",
    "outputId": "c389dc83-b63f-442f-91af-7b7aafe84125"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Original Dense Model Size Model=35.20 MiB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Model Validation Accuracy: 92.90581162324649 %\n",
      "Granular-Magnitude Pruning\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sensitivity Scan Time(mins): 2.669245207309723\n",
      "Sparsity for each Layer: {'backbone.conv0.weight': 0.45000000000000007, 'backbone.conv1.weight': 0.7500000000000002, 'backbone.conv2.weight': 0.7000000000000002, 'backbone.conv3.weight': 0.6500000000000001, 'backbone.conv4.weight': 0.6000000000000002, 'backbone.conv5.weight': 0.7000000000000002, 'backbone.conv6.weight': 0.7000000000000002, 'backbone.conv7.weight': 0.8500000000000002, 'classifier.weight': 0.9500000000000003}\n",
      "Pruning Time Consumed (mins): 6.053447723388672e-05\n",
      "Total Pruning Time Consumed (mins): 2.669320074717204\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Pruned Model has size=9.77 MiB(non-zeros) = 27.76% of Original model size\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Pruned Model has Accuracy=84.41 MiB(non-zeros) = -8.50% of Original model Accuracy\n",
      "\n",
      " \n",
      "==================== Fine-Tuning ====================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 91.88377\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:2 Train Loss: 0.00000 Validation Accuracy: 91.81363\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:3 Train Loss: 0.00000 Validation Accuracy: 91.90381\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:4 Train Loss: 0.00000 Validation Accuracy: 91.87375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:5 Train Loss: 0.00000 Validation Accuracy: 91.94389\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-Tuned Sparse model has size=9.77 MiB = 27.76% of Original model size\n",
      "Fine-Tuned Pruned Model Validation Accuracy: 91.9438877755511\n",
      "\n",
      " \n",
      "==================== Quantization-Aware Training(QAT) ====================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/98 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/fake_quantize.py:343: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at ../aten/src/ATen/native/ReduceAllOps.cpp:72.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/fake_quantize.py:343: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:677.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 92.02405\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:2 Train Loss: 0.00000 Validation Accuracy: 92.05411\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:3 Train Loss: 0.00000 Validation Accuracy: 92.04409\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:4 Train Loss: 0.00000 Validation Accuracy: 92.02405\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:5 Train Loss: 0.00000 Validation Accuracy: 92.05411\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/modules/__init__.py:97: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return torch.quantize_per_tensor(X, float(self.scale),\n",
      "/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/modules/__init__.py:98: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(self.zero_point), self.dtype)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " \n",
      "============================== Comparison Table ==============================\n",
      "+---------------------+----------------+--------------+-----------------+\n",
      "|                     | Original Model | Pruned Model | Quantized Model |\n",
      "+---------------------+----------------+--------------+-----------------+\n",
      "| Latency (ms/sample) |      37.0      |     24.2     |       19.2      |\n",
      "|     Accuracy (%)    |     92.906     |    91.944    |      92.044     |\n",
      "|      Params (M)     |      9.23      |     2.56     |        *        |\n",
      "|      Size (MiB)     |     36.949     |    36.949    |      9.293      |\n",
      "|       MAC (M)       |      606       |     606      |        *        |\n",
      "+---------------------+----------------+--------------+-----------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Channel-Wise Pruning**"
   ],
   "metadata": {
    "id": "YA_wSOZe3whu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sconces = sconce()\n",
    "sconces.model= copy.deepcopy(model)\n",
    "sconces.criterion = nn.CrossEntropyLoss() # Loss\n",
    "sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "sconces.dataloader = dataloader\n",
    "sconces.epochs = 1 #Number of time we iterate over the data\n",
    "sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sconces.experiment_name = \"vgg-cwp\"\n",
    "sconces.prune_mode = \"CWP\" # Supports Automated Pruning Ratio Detection\n"
   ],
   "metadata": {
    "id": "vtPnGXwr4wka"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compress the model Channel-Wise\n",
    "sconces.compress()"
   ],
   "metadata": {
    "id": "KT-ZQHTA0L5C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8b95c30a-fcb9-4adb-8c3a-c12b59fc1b1f"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Original Dense Model Size Model=35.20 MiB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Model Validation Accuracy: 93.13627254509018 %\n",
      "\n",
      " Channel-Wise Pruning\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sensitivity Scan Time(mins): 5.477794349193573\n",
      "Sparsity for each Layer: {'backbone.conv0.weight': 0.40000000000000013, 'backbone.conv1.weight': 0.15000000000000002, 'backbone.conv2.weight': 0.1, 'backbone.conv3.weight': 0.15000000000000002, 'backbone.conv4.weight': 0.1, 'backbone.conv5.weight': 0.1, 'backbone.conv6.weight': 0.20000000000000004} \n",
      "\n",
      "\n",
      "\n",
      "Pruning Time Consumed (mins): 0.0017029960950215657\n",
      "Total Pruning Time Consumed (mins): 5.479498942693074\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Pruned Model has size=27.21 MiB(non-zeros) = 77.29% of Original model size\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Pruned Model has Accuracy=69.00 MiB(non-zeros) = -24.14% of Original model Accuracy\n",
      "\n",
      " \n",
      "==================== Fine-Tuning ====================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 91.24248\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:2 Train Loss: 0.00000 Validation Accuracy: 91.30261\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:3 Train Loss: 0.00000 Validation Accuracy: 91.46293\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:4 Train Loss: 0.00000 Validation Accuracy: 91.46293\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:5 Train Loss: 0.00000 Validation Accuracy: 91.51303\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fine-Tuned Sparse model has size=27.21 MiB = 77.29% of Original model size\n",
      "Fine-Tuned Pruned Model Validation Accuracy: 91.51302605210421\n",
      "\n",
      " \n",
      "==================== Quantization-Aware Training(QAT) ====================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 91.63327\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:2 Train Loss: 0.00000 Validation Accuracy: 91.57315\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:3 Train Loss: 0.00000 Validation Accuracy: 91.53307\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:4 Train Loss: 0.00000 Validation Accuracy: 91.55311\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:5 Train Loss: 0.00000 Validation Accuracy: 91.48297\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/modules/__init__.py:97: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return torch.quantize_per_tensor(X, float(self.scale),\n",
      "/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/modules/__init__.py:98: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(self.zero_point), self.dtype)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " \n",
      "============================== Comparison Table ==============================\n",
      "+---------------------+----------------+--------------+-----------------+\n",
      "|                     | Original Model | Pruned Model | Quantized Model |\n",
      "+---------------------+----------------+--------------+-----------------+\n",
      "| Latency (ms/sample) |      25.0      |     20.0     |       14.5      |\n",
      "|     Accuracy (%)    |     93.136     |    91.513    |      91.443     |\n",
      "|      Params (M)     |      9.23      |     7.13     |        *        |\n",
      "|      Size (MiB)     |     36.949     |    28.565    |      7.193      |\n",
      "|       MAC (M)       |      606       |     451      |        *        |\n",
      "+---------------------+----------------+--------------+-----------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Venum Pruning a better version of Wanda Pruning**"
   ],
   "metadata": {
    "collapsed": false,
    "id": "kA4Mmt3XLlHy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Dense Model Size Model=35.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Validation Accuracy: 93.13627254509018 %\n",
      "\n",
      " Venum Pruning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity Scan Time(secs): 114.05389285087585\n",
      "Sparsity for each Layer: {'backbone.conv0.weight': 0.30000000000000004, 'backbone.conv1.weight': 0.45000000000000007, 'backbone.conv2.weight': 0.45000000000000007, 'backbone.conv3.weight': 0.5500000000000002, 'backbone.conv4.weight': 0.6000000000000002, 'backbone.conv5.weight': 0.7000000000000002, 'backbone.conv6.weight': 0.7500000000000002, 'backbone.conv7.weight': 0.8500000000000002, 'classifier.weight': 0.9500000000000003}\n",
      "Pruning Time Consumed (secs): 1701416101.321775\n",
      "Total Pruning Time Consumed (mins): 2.8907041509946185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Model has size=9.94 MiB(non-zeros) = 28.22% of Original model size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ................. Comparison Table  .................\n",
      "                Original        Pruned          Reduction Ratio\n",
      "Latency (ms)    5.9             5.8             1.0            \n",
      "MACs (M)        606             606             1.0            \n",
      "Param (M)       9.23            2.6             3.5            \n",
      "Accuracies (%)  93.136          87.735          -5.401         \n",
      "Fine-Tuned Sparse model has size=9.94 MiB = 28.22% of Original model size\n",
      "Fine-Tuned Pruned Model Validation Accuracy: 87.73547094188376\n"
     ]
    }
   ],
   "source": [
    "# from sconce import sconce\n",
    "\n",
    "# sconces = sconce()\n",
    "# sconces.model = copy.deepcopy(model)\n",
    "# sconces.criterion = nn.CrossEntropyLoss()  # Loss\n",
    "# sconces.optimizer = optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "# sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "# sconces.dataloader = dataloader\n",
    "# sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# sconces.experiment_name = \"vgg-venum\"\n",
    "# sconces.prune_mode = \"venum\"  # Supports Automated Pruning Ratio Detection\n",
    "# sconces.compress()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T07:36:59.433154884Z",
     "start_time": "2023-12-01T07:33:58.232251482Z"
    },
    "id": "nQ1mWDluLlHy",
    "outputId": "1bc289ff-111a-48da-bf26-c97c0a44108b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spiking Neural Network Compression\n"
   ],
   "metadata": {
    "id": "oJjAdrRK0aRD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install snntorch -q"
   ],
   "metadata": {
    "id": "SPatw1ex08kR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Import snntorch libraries\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from torch import optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n"
   ],
   "metadata": {
    "id": "V9qFLeGl0y24",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ae51c5c9-a5a7-416f-ac9c-01e30734e19d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-3-b898cb6c07c2>:4: DeprecationWarning: The module snntorch.backprop will be deprecated in  a future release. Writing out your own training loop will lead to substantially faster performance.\n",
      "  from snntorch import backprop\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Event Drive Data\n",
    "\n",
    "# dataloader arguments\n",
    "batch_size = 128\n",
    "data_path = \"./data/mnist\"\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    mnist_train, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    mnist_test, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n"
   ],
   "metadata": {
    "id": "zk0TCGvRKOWh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sconce import sconce\n",
    "sconces = sconce()\n",
    "# Set you Dataloader\n",
    "dataloader = {}\n",
    "dataloader[\"train\"] = train_loader\n",
    "dataloader[\"test\"] = test_loader\n",
    "sconces.dataloader = dataloader"
   ],
   "metadata": {
    "id": "9pj-ZzMQU9_Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Enable snn in sconce\n",
    "sconces.snn = True\n",
    "\n",
    "# Load your snn Model\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "snn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 64, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 4 * 4, 10),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True),\n",
    ").to('cuda')\n",
    "\n",
    "\n",
    "#Load the pretrained weights\n",
    "snn_pretrained_model_path = \"drive/MyDrive/Efficientml/Efficientml.ai/snn_model.pth\"\n",
    "snn_model.load_state_dict(torch.load(snn_pretrained_model_path))  # Model Definition\n",
    "sconces.model = snn_model"
   ],
   "metadata": {
    "id": "LzEHUCSx0hN6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "sconces.optimizer = optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "\n",
    "sconces.criterion = SF.ce_rate_loss()\n",
    "\n",
    "sconces.epochs = 10  # Number of time we iterate over the data\n",
    "sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sconces.experiment_name = \"snn-gmp\"  # Define your experiment name here\n",
    "sconces.prune_mode = \"GMP\"\n",
    "sconces.num_finetune_epochs = 1\n"
   ],
   "metadata": {
    "id": "qZLTwjV0VdJc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sconces.compress()"
   ],
   "metadata": {
    "id": "K6kWCtSk0kVq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5db1de8c-303d-416c-ee23-4463bc3d7f80"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Original Dense Model Size Model=0.11 MiB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Model Validation Accuracy: 97.11538461538461 %\n",
      "Granular-Magnitude Pruning\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity for each Layer: {'0.weight': 0.6500000000000001, '3.weight': 0.5000000000000001, '7.weight': 0.7000000000000002}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Pruned Model has size=0.05 MiB(non-zeros) = 43.13% of Original model size\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 95.97356\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " ................. Comparison Table  .................\n",
      "                Original        Pruned          Reduction Ratio\n",
      "Latency (ms)    2.09            1.43            1.5            \n",
      "MACs (M)        160             160             1.0            \n",
      "Param (M)       0.01            0.01            1.0            \n",
      "Accuracies (%)  97.115          95.974          -1.142         \n",
      "Fine-Tuned Sparse model has size=0.05 MiB = 43.13% of Original model size\n",
      "Fine-Tuned Pruned Model Validation Accuracy: 95.9735576923077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"prim::pythonop\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/usr/local/lib/python3.10/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"prim::pythonop\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
