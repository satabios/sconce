{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sathya/anaconda3/envs/test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "# import timm\n",
    "\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from torchprofile import profile_macs\n",
    "\n",
    "assert torch.cuda.is_available(), \\\n",
    "\"The current runtime does not have CUDA support.\" \\\n",
    "\"Please go to menu bar (Runtime - Change runtime type) and select GPU\"\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "# !pip uninstall sconce\n",
    "# !pip install git+https://github.com/satabios/sconce --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16*6*6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 11347126.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar10/cifar-10-python.tar.gz to data/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from torchvision.transforms import Compose\n",
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        RandomCrop(image_size, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms[split],\n",
    "  )\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=512,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "pool\n",
      "conv2\n",
      "bn2\n",
      "fc1\n",
      "fc2\n"
     ]
    }
   ],
   "source": [
    "for name, _ in Net().named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sconce import sconce, FineGrainedPruner, config\n",
    "\n",
    "# config['sparsity_dict'] = {\n",
    "#     'conv1.weight' : 0.10,\n",
    "#     'conv2.weight' : 0.10,\n",
    "#     'fc1.weight' : 0.10,\n",
    "#     'fc2.weight' : 0.10\n",
    "# }\n",
    "\n",
    "\n",
    "config['model']= Net()\n",
    "config['criterion'] = nn.CrossEntropyLoss()\n",
    "config['optimizer'] = optim.Adam(config['model'].parameters(), lr=1e-4)\n",
    "config['scheduler'] = optim.lr_scheduler.CosineAnnealingLR(config['optimizer'], T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 646720\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fc2.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel Size:\u001b[39m\u001b[39m\"\u001b[39m,sconces\u001b[39m.\u001b[39mget_model_size(count_nonzero_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m      6\u001b[0m pruner \u001b[39m=\u001b[39m FineGrainedPruner()\n\u001b[0;32m----> 7\u001b[0m pruner\u001b[39m.\u001b[39;49mprune()\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel Size:\u001b[39m\u001b[39m\"\u001b[39m,sconces\u001b[39m.\u001b[39mget_model_size(count_nonzero_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m      9\u001b[0m config[\u001b[39m'\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39mlambda\u001b[39;00m: pruner\u001b[39m.\u001b[39mapply()]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/test/sconce.py:312\u001b[0m, in \u001b[0;36mFineGrainedPruner.prune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[1;32m    310\u001b[0m     \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m: \u001b[39m# we only prune conv and fc weights\u001b[39;00m\n\u001b[1;32m    311\u001b[0m         \u001b[39m# ipdb.set_trace()\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m         config[\u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m][name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfine_grained_prune(param, config[\u001b[39m'\u001b[39;49m\u001b[39msparsity_dict\u001b[39;49m\u001b[39m'\u001b[39;49m][name])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fc2.weight'"
     ]
    }
   ],
   "source": [
    "sconces = sconce()\n",
    "sconces.train_prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
