{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:10:30.738910Z",
     "start_time": "2023-08-09T17:10:28.655979Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "# import timm\n",
    "\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from torchprofile import profile_macs\n",
    "\n",
    "# assert torch.cuda.is_available(), \\\n",
    "# \"The current runtime does not have CUDA support.\" \\\n",
    "# \"Please go to menu bar (Runtime - Change runtime type) and select GPU\"\n",
    "\n",
    "\n",
    "# import timm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "# !pip uninstall sconce\n",
    "# !pip install git+https://github.com/satabios/sconce --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:10:30.744350Z",
     "start_time": "2023-08-09T17:10:30.741082Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 6, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(6)\n",
    "        self.fc1 = nn.Linear(6*6*6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:10:32.321062Z",
     "start_time": "2023-08-09T17:10:30.746120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from torchvision.transforms import Compose\n",
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        RandomCrop(image_size, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms[split],\n",
    "  )\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=512,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:10:32.327316Z",
     "start_time": "2023-08-09T17:10:32.322383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "pool\n",
      "conv2\n",
      "bn2\n",
      "fc1\n",
      "fc2\n"
     ]
    }
   ],
   "source": [
    "for name, _ in Net().named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:10:32.340223Z",
     "start_time": "2023-08-09T17:10:32.328929Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fast_pytorch_kmeans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msconce\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sconce\n\u001b[1;32m      4\u001b[0m sconces \u001b[38;5;241m=\u001b[39m sconce()\n\u001b[1;32m      5\u001b[0m sconces\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m=\u001b[39m Net()\n",
      "File \u001b[0;32m~/Desktop/Projects/sconce/test/sconce.py:36\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchprofile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile_macs\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfast_pytorch_kmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parameter\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipdb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fast_pytorch_kmeans'"
     ]
    }
   ],
   "source": [
    "from sconce import sconce\n",
    "\n",
    "\n",
    "sconces = sconce()\n",
    "sconces.model= Net()\n",
    "sconces.criterion = nn.CrossEntropyLoss()\n",
    "sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "sconces.scheduler= optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "sconces.dataloader = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T17:12:55.301733Z",
     "start_time": "2023-08-09T17:12:23.353236Z"
    }
   },
   "outputs": [],
   "source": [
    "sconces.bitwidth = 4\n",
    "sconces.test_quant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-09T16:44:28.808306Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
