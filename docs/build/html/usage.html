<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Usage &mdash; sconce 0.57 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/my_theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/default.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=2fd344d2"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Model Compression Techniques" href="Model%20Compression%20Techniques.html" />
    <link rel="prev" title="sconce Documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            sconce
              <img src="_static/sconce-punch-bk_removed.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.57.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quick-start">Quick-Start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#define-network">Define Network:</a></li>
<li class="toctree-l3"><a class="reference internal" href="#make-a-dict-for-dataloader">Make a Dict for Dataloader</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-your-configurations">Define your Configurations:</a></li>
<li class="toctree-l3"><a class="reference internal" href="#one-roof-solution-train-compress-deploy">One Roof Solution [Train -&gt; Compress -&gt; Deploy]:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-sconce">Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sconce.sconce"><code class="docutils literal notranslate"><span class="pre">sconce</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.CWP_Pruning"><code class="docutils literal notranslate"><span class="pre">sconce.CWP_Pruning()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.GMP_Pruning"><code class="docutils literal notranslate"><span class="pre">sconce.GMP_Pruning()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.GMP_apply"><code class="docutils literal notranslate"><span class="pre">sconce.GMP_apply()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.apply_channel_sorting"><code class="docutils literal notranslate"><span class="pre">sconce.apply_channel_sorting()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.channel_prune"><code class="docutils literal notranslate"><span class="pre">sconce.channel_prune()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.compare_models"><code class="docutils literal notranslate"><span class="pre">sconce.compare_models()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.compress"><code class="docutils literal notranslate"><span class="pre">sconce.compress()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.evaluate"><code class="docutils literal notranslate"><span class="pre">sconce.evaluate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.fine_grained_prune"><code class="docutils literal notranslate"><span class="pre">sconce.fine_grained_prune()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.forward_pass_snn"><code class="docutils literal notranslate"><span class="pre">sconce.forward_pass_snn()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_input_channel_importance"><code class="docutils literal notranslate"><span class="pre">sconce.get_input_channel_importance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_model_macs"><code class="docutils literal notranslate"><span class="pre">sconce.get_model_macs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_model_size"><code class="docutils literal notranslate"><span class="pre">sconce.get_model_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_model_sparsity"><code class="docutils literal notranslate"><span class="pre">sconce.get_model_sparsity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_num_channels_to_keep"><code class="docutils literal notranslate"><span class="pre">sconce.get_num_channels_to_keep()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_num_parameters"><code class="docutils literal notranslate"><span class="pre">sconce.get_num_parameters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.get_sparsity"><code class="docutils literal notranslate"><span class="pre">sconce.get_sparsity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.measure_latency"><code class="docutils literal notranslate"><span class="pre">sconce.measure_latency()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.plot_weight_distribution"><code class="docutils literal notranslate"><span class="pre">sconce.plot_weight_distribution()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.sensitivity_scan"><code class="docutils literal notranslate"><span class="pre">sconce.sensitivity_scan()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sconce.sconce.train"><code class="docutils literal notranslate"><span class="pre">sconce.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Model%20Compression%20Techniques.html">Model Compression Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sconce</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Usage</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/usage.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h1>
<section id="installation">
<span id="id1"></span><h2>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h2>
<p>Run the following to install:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python
$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>sconce
</pre></div>
</div>
<p>To install sconce from source instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/satabios/sconce
$ cd sconce
$ python setup.py install
</pre></div>
</div>
<p>To install sconce with conda:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install -c conda-forge sconce
</pre></div>
</div>
</section>
<section id="quick-start">
<h2>Quick-Start<a class="headerlink" href="#quick-start" title="Link to this heading"></a></h2>
<section id="define-network">
<h3>Define Network:<a class="headerlink" href="#define-network" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">6</span><span class="o">*</span><span class="mi">6</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
<section id="make-a-dict-for-dataloader">
<h3>Make a Dict for Dataloader<a class="headerlink" href="#make-a-dict-for-dataloader" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">Compose</span><span class="p">([</span>
        <span class="n">RandomCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
        <span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">ToTensor</span><span class="p">(),</span>
    <span class="p">]),</span>
    <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">}</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]:</span>
  <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data/cifar10&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
  <span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]:</span>
  <span class="n">dataloader</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="define-your-configurations">
<h3>Define your Configurations:<a class="headerlink" href="#define-your-configurations" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define all parameters</span>

<span class="kn">from</span> <span class="nn">sconce</span> <span class="kn">import</span> <span class="n">sconce</span>

<span class="n">sconces</span> <span class="o">=</span> <span class="n">sconce</span><span class="p">()</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">=</span> <span class="n">Net</span><span class="p">()</span> <span class="c1"># Model Definition</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> <span class="c1"># Loss</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1">#Number of time we iterate over the data</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;vgg-gmp&quot;</span> <span class="c1"># Define your experiment name here</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">prune_mode</span> <span class="o">=</span> <span class="s2">&quot;GMP&quot;</span> <span class="c1"># Prune Mode: Currently supporting &quot;GMP&quot;(Supports Automated Pruning Ratio Detection), &quot;CWP&quot;. Future supports for &quot;OBC&quot; and &quot;sparseGPT&quot;</span>
</pre></div>
</div>
</section>
<section id="one-roof-solution-train-compress-deploy">
<h3>One Roof Solution [Train -&gt; Compress -&gt; Deploy]:<a class="headerlink" href="#one-roof-solution-train-compress-deploy" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sconces</span><span class="o">.</span><span class="n">compress</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="module-sconce">
<span id="features"></span><h2>Features<a class="headerlink" href="#module-sconce" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="sconce.sconce">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sconce.</span></span><span class="sig-name descname"><span class="pre">sconce</span></span><a class="headerlink" href="#sconce.sconce" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.CWP_Pruning">
<span class="sig-name descname"><span class="pre">CWP_Pruning</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.CWP_Pruning" title="Link to this definition"></a></dt>
<dd><p>Applies channel pruning to the model using the specified channel pruning ratio.
Returns the pruned model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.GMP_Pruning">
<span class="sig-name descname"><span class="pre">GMP_Pruning</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.GMP_Pruning" title="Link to this definition"></a></dt>
<dd><p>Applies Group-wise Magnitude Pruning (GMP) to the model’s convolutional and fully-connected weights.
The pruning is performed based on the sparsity levels specified in the <cite>sparsity_dict</cite> attribute.
The pruned weights are stored in the <cite>masks</cite> attribute.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.GMP_apply">
<span class="sig-name descname"><span class="pre">GMP_apply</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.GMP_apply" title="Link to this definition"></a></dt>
<dd><p>Applies the Group Masking Procedure (GMP) to the model’s parameters.</p>
<p>This function iterates over the model’s named parameters and applies the corresponding mask
if it exists in the <cite>masks</cite> dictionary. The mask is applied by element-wise multiplication
with the parameter tensor.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>self (object): The <cite>sconce</cite> object.</p>
</dd>
<dt>Returns:</dt><dd><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.apply_channel_sorting">
<span class="sig-name descname"><span class="pre">apply_channel_sorting</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.apply_channel_sorting" title="Link to this definition"></a></dt>
<dd><p>Applies channel sorting to the model’s convolutional and batch normalization layers.
Returns a copy of the model with sorted channels.</p>
<p>Returns:
model (torch.nn.Module): A copy of the model with sorted channels.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.channel_prune">
<span class="sig-name descname"><span class="pre">channel_prune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="headerlink" href="#sconce.sconce.channel_prune" title="Link to this definition"></a></dt>
<dd><p>Apply channel pruning to each of the conv layer in the backbone
Note that for prune_ratio, we can either provide a floating-point number,
indicating that we use a uniform pruning rate for all layers, or a list of
numbers to indicate per-layer pruning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.compare_models">
<span class="sig-name descname"><span class="pre">compare_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_dense_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pruned_fine_tuned_model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.compare_models" title="Link to this definition"></a></dt>
<dd><p>Compares the performance of two PyTorch models: an original dense model and a pruned and fine-tuned model.
Prints a table of metrics including latency, MACs, and model size for both models and their reduction ratios.</p>
<p>Args:
- original_dense_model: a PyTorch model object representing the original dense model
- pruned_fine_tuned_model: a PyTorch model object representing the pruned and fine-tuned model</p>
<p>Returns: None</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.compress">
<span class="sig-name descname"><span class="pre">compress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span></span><a class="headerlink" href="#sconce.sconce.compress" title="Link to this definition"></a></dt>
<dd><p>Compresses the neural network model using either Granular-Magnitude Pruning (GMP) or Channel-Wise Pruning (CWP).
If GMP is used, the sensitivity of each layer is first scanned and then the Fine-Grained Pruning is applied.
If CWP is used, the Channel-Wise Pruning is applied directly.
After pruning, the model is fine-tuned using Stochastic Gradient Descent (SGD) optimizer with Cosine Annealing
Learning Rate Scheduler.
The original dense model and the pruned fine-tuned model are saved in separate files.
Finally, the validation accuracy and the size of the pruned model are printed.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>verbose (bool): If True, prints the validation accuracy and the size of the pruned model. Default is True.</p>
</dd>
<dt>Returns:</dt><dd><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluates the model on the test dataset and returns the accuracy.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>verbose (bool): If True, prints the test accuracy.</p>
</dd>
<dt>Returns:</dt><dd><p>float: The test accuracy as a percentage.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.fine_grained_prune">
<span class="sig-name descname"><span class="pre">fine_grained_prune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#sconce.sconce.fine_grained_prune" title="Link to this definition"></a></dt>
<dd><p>magnitude-based pruning for single tensor
:param tensor: torch.(cuda.)Tensor, weight of conv/fc layer
:param sparsity: float, pruning sparsity</p>
<blockquote>
<div><p>sparsity = #zeros / #elements = 1 - #nonzeros / #elements</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.(cuda.)Tensor, mask for zeros</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.forward_pass_snn">
<span class="sig-name descname"><span class="pre">forward_pass_snn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mem_out_rec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.forward_pass_snn" title="Link to this definition"></a></dt>
<dd><p>snn Forward Pass</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – Input from the data loader</p></li>
<li><p><strong>mem_out_rec</strong> – Record Membrane Potential, if set to a value return both Membrane potential and Spikes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Return the Membrane Potential output of the network</p>
</dd>
</dl>
<p># :example:
# .. jupyter-execute::
#
#   import sconce
#   print(your_package_name.some_documented_func(1))</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_input_channel_importance">
<span class="sig-name descname"><span class="pre">get_input_channel_importance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.get_input_channel_importance" title="Link to this definition"></a></dt>
<dd><p>Computes the importance of each input channel in a weight tensor.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>weight (torch.Tensor): The weight tensor to compute channel importance for.</p>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: A tensor containing the importance of each input channel.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_model_macs">
<span class="sig-name descname"><span class="pre">get_model_macs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_model_macs" title="Link to this definition"></a></dt>
<dd><p>Calculates the number of multiply-accumulate operations (MACs) required to run the given model with the given inputs.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model: The model to profile.
inputs: The inputs to the model.</p>
</dd>
<dt>Returns:</dt><dd><p>The number of MACs required to run the model with the given inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_model_size">
<span class="sig-name descname"><span class="pre">get_model_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_nonzero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_model_size" title="Link to this definition"></a></dt>
<dd><p>calculate the model size in bits
:param data_width: #bits per element
:param count_nonzero_only: only count nonzero weights</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_model_sparsity">
<span class="sig-name descname"><span class="pre">get_model_sparsity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_model_sparsity" title="Link to this definition"></a></dt>
<dd><p>Calculate the sparsity of the given PyTorch model.</p>
<p>Sparsity is defined as the ratio of the number of zero-valued weights to the total number of weights in the model.
This function iterates over all parameters in the model and counts the number of non-zero values and the total
number of values.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The PyTorch model to calculate sparsity for.</p>
</dd>
<dt>Returns:</dt><dd><p>float: The sparsity of the model, defined as 1 - (# non-zero weights / # total weights).</p>
</dd>
<dt>calculate the sparsity of the given model</dt><dd><p>sparsity = #zeros / #elements = 1 - #nonzeros / #elements</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_num_channels_to_keep">
<span class="sig-name descname"><span class="pre">get_num_channels_to_keep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_num_channels_to_keep" title="Link to this definition"></a></dt>
<dd><p>A function to calculate the number of layers to PRESERVE after pruning
Note that preserve_rate = 1. - prune_ratio</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_num_parameters">
<span class="sig-name descname"><span class="pre">get_num_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_nonzero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_num_parameters" title="Link to this definition"></a></dt>
<dd><p>Calculate the total number of parameters of a PyTorch model.</p>
<dl>
<dt>Args:</dt><dd><p>model (nn.Module): The PyTorch model to count the parameters of.
count_nonzero_only (bool, optional): Whether to count only the nonzero weights.</p>
<blockquote>
<div><p>Defaults to False.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt><dd><p>int: The total number of parameters of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.get_sparsity">
<span class="sig-name descname"><span class="pre">get_sparsity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span></span><a class="headerlink" href="#sconce.sconce.get_sparsity" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>calculate the sparsity of the given tensor</dt><dd><p>sparsity = #zeros / #elements = 1 - #nonzeros / #elements</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.measure_latency">
<span class="sig-name descname"><span class="pre">measure_latency</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_warmup</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.measure_latency" title="Link to this definition"></a></dt>
<dd><p>Measures the average latency of a given PyTorch model by running it on a dummy input multiple times.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The PyTorch model to measure the latency of.
dummy_input (torch.Tensor): A dummy input to the model.
n_warmup (int, optional): The number of warmup iterations to run before measuring the latency. Defaults to 20.
n_test (int, optional): The number of iterations to run to measure the latency. Defaults to 100.</p>
</dd>
<dt>Returns:</dt><dd><p>float: The average latency of the model in milliseconds.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.plot_weight_distribution">
<span class="sig-name descname"><span class="pre">plot_weight_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_nonzero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.plot_weight_distribution" title="Link to this definition"></a></dt>
<dd><p>Plots the weight distribution of the model’s named parameters.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>bins (int): Number of bins to use in the histogram. Default is 256.
count_nonzero_only (bool): If True, only non-zero weights will be plotted. Default is False.</p>
</dd>
<dt>Returns:</dt><dd><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.sensitivity_scan">
<span class="sig-name descname"><span class="pre">sensitivity_scan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dense_model_accuracy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scan_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scan_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scan_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sconce.sconce.sensitivity_scan" title="Link to this definition"></a></dt>
<dd><p>Scans the sensitivity of the model to weight pruning by gradually increasing the sparsity of each layer’s weights
and measuring the resulting accuracy. Returns a dictionary mapping layer names to the sparsity values that resulted
in the highest accuracy for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dense_model_accuracy</strong> – the accuracy of the original dense model</p></li>
<li><p><strong>scan_step</strong> – the step size for the sparsity scan</p></li>
<li><p><strong>scan_start</strong> – the starting sparsity for the scan</p></li>
<li><p><strong>scan_end</strong> – the ending sparsity for the scan</p></li>
<li><p><strong>verbose</strong> – whether to print progress information during the scan</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a dictionary mapping layer names to the sparsity values that resulted in the highest accuracy for each layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sconce.sconce.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span></span><a class="headerlink" href="#sconce.sconce.train" title="Link to this definition"></a></dt>
<dd><p>Trains the model for a specified number of epochs using the specified dataloader and optimizer.
If fine-tuning is enabled, the number of epochs is set to <cite>num_finetune_epochs</cite>.
The function also saves the model state after each epoch if the validation accuracy improves.</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="sconce Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Model%20Compression%20Techniques.html" class="btn btn-neutral float-right" title="Model Compression Techniques" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Sathyaprakash.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>