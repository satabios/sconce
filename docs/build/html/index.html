<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sconce Documentation &mdash; sconce 0.57 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/my_theme.css" />
      <link rel="stylesheet" href="_static/css/default.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            sconce
              <img src="_static/sconce-punch-bk_removed.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.57.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="Model%20Compression%20Techniques.html">Model Compression Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="Auto-Sensitivity-Picker.html">Efficient-Hyperparameter Auto Sensitivity Seach</a></li>
<li class="toctree-l1"><a class="reference internal" href="Features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeline.html">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">sconce</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">sconce Documentation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sconce-documentation">
<h1>sconce Documentation<a class="headerlink" href="#sconce-documentation" title="Permalink to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<a class="reference external image-reference" href="https://sconce.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/sconce/badge/?version=latest" /></a>
<a class="reference internal image-reference" href="https://github.com/satabios/sconce/blob/main/docs/source/images/sconce-punch-bk_removed.png?raw=true"><img alt="https://github.com/satabios/sconce/blob/main/docs/source/images/sconce-punch-bk_removed.png?raw=true" class="align-center" src="https://github.com/satabios/sconce/blob/main/docs/source/images/sconce-punch-bk_removed.png?raw=true" style="width: 400px; height: 400px;" /></a>
<p>Advancement of deep learning has been largely driven by the availability of large datasets and the computational power to train large models.
The amount of complexity increases with each day passing and it is becoming increasingly difficult to train these models. Neverthless, infer
the models efficiently on hardware.</p>
<p>However, the brain is able to learn from a few examples and is extremely energy efficient(Psst.. that too sparsely). Humans tend solve problems from their lens of perspective,
and thus we comprehend the universe through mathematical models. One such ideation is the concept of gradient descent or other optimization techniques
that we use to train our models. However, the brain does not use gradient descent to learn. It is still a mystery how the brain learns and how it is able to
solve complex problems with such ease.</p>
<img alt="https://github.com/satabios/sconce/blob/main/docs/source/images/sconce-pipeline.png?raw=true" class="align-center" src="https://github.com/satabios/sconce/blob/main/docs/source/images/sconce-pipeline.png?raw=true" />
<p>To bridge this gap, this package aids to perform a series of aids:</p>
<ul class="simple">
<li><p>Make <strong>Training</strong>, <strong>Testing</strong>, <strong>Inference</strong>, <strong>Model Profiling</strong>, etc.. pipelined. Thus easing your way through research and development.</p></li>
<li><p><strong>Compress</strong> the model through <strong>Pruning</strong>, <strong>Optimal Brain Compression</strong>, etc… This allows lesser usage of CPM(Computation, Power, Memory) and thus making it more efficient.</p></li>
<li><p><strong>Quantize</strong> the model to make it more efficient for hardware Deployment/Inferences.</p></li>
<li><p>Leverage <strong>Sparsity</strong> in the model to make it more efficient for hardware Deployment/Inferences.</p></li>
<li><p><strong>Deployments</strong> of the model on hardware.</p></li>
<li><p>Support <a class="reference external" href="https://github.com/jeshraghian/snntorch">Spiking Neural Networks(snnTorch)</a> in this compression pipeline [Future integerations are expected].</p></li>
<li><p><strong>Auto-Sensitivity Scan</strong>: Each model would require a set of ingredients of its own to make it efficient. sconce enables an auto-search algorithm that picks the best possible solution from a corpus amount of possible techniques in the fastest manner possible with the least amount of human intervention.</p></li>
</ul>
<p>If you like this project, please consider starring ⭐ this repo as it is the easiest and best way to support it.</p>
<p>Let us know if you are using sconce in any interesting work, research or blogs, as we would love to hear more about it!
If you have issues, comments, or are looking for advice on training spiking neural networks, you can open an issue, a discussion,
or chat in our <a class="reference external" href="https://discord.gg/GKwXMrZr">discord</a> channel.</p>
<section id="sconce-structure">
<h3>sconce Structure<a class="headerlink" href="#sconce-structure" title="Permalink to this heading"></a></h3>
<p>sconce contains the following components:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Component</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/usage.html#module-sconce">sconce.train</a></p></td>
<td><p>a spiking neuron library like torch.nn, deeply integrated with autograd</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/usage.html#module-sconce">sconce.measure_latency</a></p></td>
<td><p>Compares the performance of two PyTorch models: an original dense model and a pruned and fine-tuned model. Prints a table of metrics including latency, MACs, and model size for both models and their reduction ratios.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/usage.html#module-sconce">sconce.prune_mode</a></p></td>
<td><p>Currently supporting Gradual Magnitude Pruning(GMP), L1/L2 based Channel Wise Pruning(CWP), OBC, sparsegpt, etc…</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/usage.html#module-sconce">sconce.quantize</a></p></td>
<td><p>Quantize the computations of the model to make it more efficient for hardware Deployment/Inferences.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/usage.html#module-sconcel">sconce.compress</a></p></td>
<td><p>Automated compression pipeline encompassing of Pruning, Quantization, and Sparsification.</p></td>
</tr>
</tbody>
</table>
<p><strong>sconce</strong> is designed to be intuitively used with PyTorch, compression for Linear, Convolutional and Attention blocks are supported.</p>
<p>At present, we are working on adding support for more compression techniques and more models.
The package envisions to be a one stop solution for all your compression needs and deployed on resource constrained devices.
Provided that the network models and tensors are loaded onto CUDA, sconce takes advantage of GPU acceleration in the same way as PyTorch.</p>
<p>sconce is a work in progress, and we welcome contributions from the community.</p>
</section>
<section id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading"></a></h3>
<p>The following packages need to be installed to use sconce:</p>
<ul class="simple">
<li><p>torch &gt;= 1.1.0</p></li>
<li><p>numpy &gt;= 1.17</p></li>
<li><p>torchprofile</p></li>
<li><p>matplotlib</p></li>
<li><p>snntorch</p></li>
</ul>
<p>They are automatically installed if sconce is installed using the pip command. Ensure the correct version of torch is installed for your system to enable CUDA compatibility.</p>
</section>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h3>
<p>Run the following to install:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python
$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>sconce
</pre></div>
</div>
<p>To install sconce from source instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/satabios/sconce
$ cd sconce
$ python setup.py install
</pre></div>
</div>
</section>
<section id="api-examples">
<h3>API &amp; Examples<a class="headerlink" href="#api-examples" title="Permalink to this heading"></a></h3>
<p>A complete API is available <a class="reference external" href="https://sconce.readthedocs.io/">here</a>. Examples, tutorials and Colab notebooks are provided.</p>
</section>
<section id="quickstart">
<h3>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this heading"></a></h3>
<a class="reference external image-reference" href="https://colab.research.google.com/github/satabios/sconce/blob/main/tutorials/Compression%20Pipeline.ipynb#"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>
<p>Here are a few ways you can get started with sconce:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/satabios/sconce/blob/main/tutorials/Compression%20Pipeline.ipynb">Quickstart Notebook (Opens in Colab)</a></p></li>
<li><p><a class="reference external" href="https://sconce.readthedocs.io/">The API Reference</a></p></li>
<li><p><a class="reference external" href="https://sconce.readthedocs.io/en/latest/tutorials/index.html">Tutorials</a></p></li>
</ul>
</section>
</section>
</section>
<section id="id1">
<h1>Quickstart:<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h1>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">6</span><span class="o">*</span><span class="mi">6</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">Compose</span><span class="p">([</span>
        <span class="n">RandomCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
        <span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">ToTensor</span><span class="p">(),</span>
    <span class="p">]),</span>
    <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">}</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]:</span>
  <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data/cifar10&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
  <span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]:</span>
  <span class="n">dataloader</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define all parameters</span>

<span class="kn">from</span> <span class="nn">sconce</span> <span class="kn">import</span> <span class="n">sconce</span>

<span class="n">sconces</span> <span class="o">=</span> <span class="n">sconce</span><span class="p">()</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">=</span> <span class="n">Net</span><span class="p">()</span> <span class="c1"># Model Definition</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> <span class="c1"># Loss</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1">#Number of time we iterate over the data</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;vgg-gmp&quot;</span> <span class="c1"># Define your experiment name here</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">prune_mode</span> <span class="o">=</span> <span class="s2">&quot;GMP&quot;</span> <span class="c1"># Prune Mode: Currently supporting &quot;GMP&quot;(Supports Automated Pruning Ratio Detection), &quot;CWP&quot;. Future supports for &quot;OBC&quot; and &quot;sparseGPT&quot;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sconces</span><span class="o">.</span><span class="n">compress</span><span class="p">()</span>
</pre></div>
</div>
<p>If you’re ready to contribute to sconce, ping on <a class="reference external" href="https://discord.gg/GKwXMrZr">discord</a> channel.</p>
<p>sconce is solely being maintained by <a class="reference external" href="https://satabios.github.io/portfolio/">Sathyaprakash Narayanan</a>.</p>
<p>Special Thanks:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.jasoneshraghian.com/">Prof. and Mentor Jason K. Eshraghian</a> and his pet <a class="reference external" href="https://github.com/jeshraghian/snntorch/">snnTorch</a> (extensively inspired from snnTorch to build and document sconce)</p></li>
<li><p><a class="reference external" href="https://hanlab.mit.edu/">Prof. Song Han</a> for his coursework MIT6.5940 and many other projects like <a class="reference external" href="https://github.com/mit-han-lab/torchsparse/">torchsparse</a>.</p></li>
<li><p><a class="reference external" href="https://github.com/neuralmagic/">Neural Magic(Elias Frantar, Denis Kuznedelev, etc…)</a> for <a class="reference external" href="https://github.com/IST-DASLab/OBC/">OBC</a> and <a class="reference external" href="https://github.com/IST-DASLab/sparsegpt/">sparseGPT</a>.</p></li>
</ul>
<p>sconce source code is published under the terms of the MIT License.
sconce’s documentation is licensed under a Creative Commons Attribution-Share Alike 3.0 Unported License (<a class="reference external" href="https://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a>).</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="Model%20Compression%20Techniques.html">Model Compression Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="Auto-Sensitivity-Picker.html">Efficient-Hyperparameter Auto Sensitivity Seach</a></li>
<li class="toctree-l1"><a class="reference internal" href="Features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeline.html">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
</ul>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage.html" class="btn btn-neutral float-right" title="Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Sathyaprakash.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>