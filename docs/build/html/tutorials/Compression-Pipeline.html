<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Compression Pipeline &mdash; sconce 0.57 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/my_theme.css" />
      <link rel="stylesheet" href="../_static/css/default.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2fd344d2"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pruning" href="Pruning.html" />
    <link rel="prev" title="Tutorials" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            sconce
              <img src="../_static/sconce-punch-bk_removed.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.57.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Model%20Compression%20Techniques.html">Model Compression Techniques</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Compression Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#compress-the-model-granuarly">Compress the model Granuarly</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#spiking-neural-network-compression">Spiking Neural Network Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pruning.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Quantization.html">Quantization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Auto-Sensitivity-Picker.html">Efficient-Hyperparameter Auto Sensitivity Seach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../timeline.html">Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sconce</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Compression Pipeline</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/Compression-Pipeline.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="compression-pipeline">
<h1>Compression Pipeline<a class="headerlink" href="#compression-pipeline" title="Link to this heading"></a></h1>
<p>!pip install sconce -q</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from collections import defaultdict, OrderedDict

import numpy as np
import torch
from torch import nn
from torch.optim import *
from torch.optim.lr_scheduler import *
from torch.utils.data import DataLoader
from torchvision.datasets import *
from torchvision.transforms import *
import torch.optim as optim

assert torch.cuda.is_available(), \
&quot;The current runtime does not have CUDA support.&quot; \
&quot;Please go to menu bar (Runtime - Change runtime type) and select GPU&quot;
</pre></div>
</div>
<p>Load the Pre-Trained Model Weights</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from google.colab import drive
drive.mount(&#39;/content/drive&#39;)
model_path = &quot;drive/MyDrive/Efficientml/Efficientml.ai/vgg.cifar.pretrained.pth&quot;
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Mounted</span> <span class="n">at</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">drive</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class VGG(nn.Module):
  ARCH = [64, 128, &#39;M&#39;, 256, 256, &#39;M&#39;, 512, 512, &#39;M&#39;, 512, 512, &#39;M&#39;]

  def __init__(self) -&gt; None:
    super().__init__()

    layers = []
    counts = defaultdict(int)

    def add(name: str, layer: nn.Module) -&gt; None:
      layers.append((f&quot;{name}{counts[name]}&quot;, layer))
      counts[name] += 1

    in_channels = 3
    for x in self.ARCH:
      if x != &#39;M&#39;:
        # conv-bn-relu
        add(&quot;conv&quot;, nn.Conv2d(in_channels, x, 3, padding=1, bias=False))
        add(&quot;bn&quot;, nn.BatchNorm2d(x))
        add(&quot;relu&quot;, nn.ReLU(True))
        in_channels = x
      else:
        # maxpool
        add(&quot;pool&quot;, nn.MaxPool2d(2))

    self.backbone = nn.Sequential(OrderedDict(layers))
    self.classifier = nn.Linear(512, 10)

  def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
    # backbone: [N, 3, 32, 32] =&gt; [N, 512, 2, 2]
    x = self.backbone(x)

    # avgpool: [N, 512, 2, 2] =&gt; [N, 512]
    x = x.mean([2, 3])

    # classifier: [N, 512] =&gt; [N, 10]
    x = self.classifier(x)
    return x


#load the pretrained model

model = VGG().cuda()
checkpoint = torch.load(model_path)
model.load_state_dict(checkpoint[&#39;state_dict&#39;])
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">All</span> <span class="n">keys</span> <span class="n">matched</span> <span class="n">successfully</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Setup the Dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>image_size = 32
transforms = {
    &quot;train&quot;: transforms.Compose([
        RandomCrop(image_size, padding=4),
        RandomHorizontalFlip(),
        ToTensor(),
    ]),
    &quot;test&quot;: ToTensor(),
}
dataset = {}
for split in [&quot;train&quot;, &quot;test&quot;]:

    dataset[split] = CIFAR10(
    root=&quot;data/cifar10&quot;,
    train=(split == &quot;train&quot;),
    download=True,
    transform=transforms[split],
    )

dataloader = {}
for split in [&#39;train&#39;, &#39;test&#39;]:
  dataloader[split] = DataLoader(
    dataset[split],
    batch_size=512,
    shuffle=(split == &#39;train&#39;),
    num_workers=0,
    pin_memory=True,
  )
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Downloading</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">cs</span><span class="o">.</span><span class="n">toronto</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">kriz</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span> <span class="n">to</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>100%|██████████| 170498071/170498071 [00:10&lt;00:00, 16502419.73it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Extracting</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span> <span class="n">to</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span>
<span class="n">Files</span> <span class="n">already</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span>
</pre></div>
</div>
<p>sconce Configurations</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sconce import sconce


sconces = sconce()
sconces.model= model
sconces.criterion = nn.CrossEntropyLoss() # Loss
sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)
sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)
sconces.dataloader = dataloader
sconces.epochs = 1 #Number of time we iterate over the data
sconces.device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
sconces.experiment_name = &quot;vgg-gmp&quot;
sconces.prune_mode = &quot;GMP&quot; # Supports Automated Pruning Ratio Detection
</pre></div>
</div>
<p>Train and Validated the Model on the given dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Train the model
sconces.train()
# Evaludate the model
sconces.evaluate()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">1</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">92.92585</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">92.92585170340682</span>
</pre></div>
</div>
<p>Magic Happens here: Compress the model(GMP pruning is set as the prune
mode[sconces.prune_mode] above)</p>
<section id="compress-the-model-granuarly">
<h2>Compress the model Granuarly<a class="headerlink" href="#compress-the-model-granuarly" title="Link to this heading"></a></h2>
<p>sconces.compress()</p>
<p><strong>Channel-Wise Pruning</strong></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sconces = sconce()
sconces.model= model
sconces.criterion = nn.CrossEntropyLoss() # Loss
sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)
sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)
sconces.dataloader = dataloader
sconces.epochs = 1 #Number of time we iterate over the data
sconces.device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
sconces.experiment_name = &quot;vgg-cwp&quot;
sconces.prune_mode = &quot;CWP&quot; # Supports Automated Pruning Ratio Detection
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Compress the model Channel-Wise
sconces.compress()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Dense</span> <span class="n">Model</span> <span class="n">Size</span> <span class="n">Model</span><span class="o">=</span><span class="mf">21.94</span> <span class="n">MiB</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">92.82565130260521</span> <span class="o">%</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">Channel</span><span class="o">-</span><span class="n">Wise</span> <span class="n">Pruning</span>
<span class="n">Sparsity</span> <span class="k">for</span> <span class="n">each</span> <span class="n">Layer</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;backbone.conv0.weight&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;backbone.conv1.weight&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;backbone.conv2.weight&#39;</span><span class="p">:</span> <span class="mf">0.15000000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv3.weight&#39;</span><span class="p">:</span> <span class="mf">0.15000000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv4.weight&#39;</span><span class="p">:</span> <span class="mf">0.25000000000000006</span><span class="p">,</span> <span class="s1">&#39;backbone.conv5.weight&#39;</span><span class="p">:</span> <span class="mf">0.20000000000000004</span><span class="p">,</span> <span class="s1">&#39;backbone.conv6.weight&#39;</span><span class="p">:</span> <span class="mf">0.40000000000000013</span><span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Pruned</span> <span class="n">Model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">12.81</span> <span class="n">MiB</span><span class="p">(</span><span class="n">non</span><span class="o">-</span><span class="n">zeros</span><span class="p">)</span> <span class="o">=</span> <span class="mf">58.41</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">1</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">89.83968</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">2</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">89.97996</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">3</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">90.21042</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">4</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">90.39078</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">5</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">90.59118</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="o">.................</span> <span class="n">Comparison</span> <span class="n">Table</span>  <span class="o">.................</span>
                <span class="n">Original</span>        <span class="n">Pruned</span>          <span class="n">Reduction</span> <span class="n">Ratio</span>
<span class="n">Latency</span> <span class="p">(</span><span class="n">ms</span><span class="p">)</span>    <span class="mf">3.87</span>            <span class="mf">2.12</span>            <span class="mf">1.8</span>
<span class="n">MACs</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>        <span class="mi">606</span>             <span class="mi">410</span>             <span class="mf">1.5</span>
<span class="n">Param</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>       <span class="mf">5.75</span>            <span class="mf">5.44</span>            <span class="mf">1.1</span>
<span class="n">Accuracies</span> <span class="p">(</span><span class="o">%</span><span class="p">)</span>  <span class="mf">92.826</span>          <span class="mf">90.591</span>          <span class="o">-</span><span class="mf">2.234</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Sparse</span> <span class="n">model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">20.76</span> <span class="n">MiB</span> <span class="o">=</span> <span class="mf">94.62</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Pruned</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">90.59118236472946</span>
</pre></div>
</div>
<h1><center><p>Benchmarking on RTX4090</p>
</center></h1><ul class="simple">
<li><p><strong>Dense Model</strong> has a size of <em>35.20MiB</em> and accuracy of <em>92.89%</em>.</p></li>
<li><p><strong>Post Pruning(GMP) Pruned Model</strong> size <em>21.94MiB</em> with accuracy of
<em>92.86%</em>.</p></li>
<li><p><strong>Post Pruning(CMP) Pruned Model</strong> size <em>20.76MiB</em> with accuracy of
<em>90.59%</em>.</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Original</p></th>
<th class="head"><p>CWP
Pruned</p></th>
<th class="head"><p>GMP
Pruned</p></th>
<th class="head"><p>CWP
R
eduction
Ratio</p></th>
<th class="head"><p>GMP
R
eduction
Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><ul class="simple">
<li></li>
</ul>
<p><em>Latency
(ms)
[↓]*</em></p>
</td>
<td><p>5.90</p></td>
<td><p>4.20</p></td>
<td><p>5.70</p></td>
<td><p>1.4</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p><strong>MACs
(M)
[↓]</strong></p></td>
<td><p>606</p></td>
<td><p>406</p></td>
<td><p>606</p></td>
<td><p>1.5</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p><strong>Param
(M)[No
n-Zeros]
[↓]</strong></p></td>
<td><p>9.23</p></td>
<td><p>5.36</p></td>
<td><p>4.42</p></td>
<td><p>1.7</p></td>
<td><p>2.1</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Ac
curacies
(%)
[↑]</strong></p></td>
<td><p>93.136</p></td>
<td><p>90.391</p></td>
<td><p>92.946</p></td>
<td><p>-2.745</p></td>
<td><p>-0.19</p></td>
</tr>
</tbody>
</table>
<p>The catch is that GMP stores the zeros in the weight, which contributes
to the higher values of model size.</p>
<p><strong>Venum Pruning a better version of Wanda Pruning</strong></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sconce import sconce

sconces = sconce()
sconces.model = model
sconces.criterion = nn.CrossEntropyLoss()  # Loss
sconces.optimizer = optim.Adam(sconces.model.parameters(), lr=1e-4)
sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)
sconces.dataloader = dataloader
sconces.device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
sconces.experiment_name = &quot;vgg-venum&quot;
sconces.prune_mode = &quot;venum&quot;  # Supports Automated Pruning Ratio Detection
sconces.compress()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Dense</span> <span class="n">Model</span> <span class="n">Size</span> <span class="n">Model</span><span class="o">=</span><span class="mf">35.20</span> <span class="n">MiB</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.13627254509018</span> <span class="o">%</span>

 <span class="n">Venum</span> <span class="n">Pruning</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sensitivity</span> <span class="n">Scan</span> <span class="n">Time</span><span class="p">(</span><span class="n">secs</span><span class="p">):</span> <span class="mf">114.05389285087585</span>
<span class="n">Sparsity</span> <span class="k">for</span> <span class="n">each</span> <span class="n">Layer</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;backbone.conv0.weight&#39;</span><span class="p">:</span> <span class="mf">0.30000000000000004</span><span class="p">,</span> <span class="s1">&#39;backbone.conv1.weight&#39;</span><span class="p">:</span> <span class="mf">0.45000000000000007</span><span class="p">,</span> <span class="s1">&#39;backbone.conv2.weight&#39;</span><span class="p">:</span> <span class="mf">0.45000000000000007</span><span class="p">,</span> <span class="s1">&#39;backbone.conv3.weight&#39;</span><span class="p">:</span> <span class="mf">0.5500000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv4.weight&#39;</span><span class="p">:</span> <span class="mf">0.6000000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv5.weight&#39;</span><span class="p">:</span> <span class="mf">0.7000000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv6.weight&#39;</span><span class="p">:</span> <span class="mf">0.7500000000000002</span><span class="p">,</span> <span class="s1">&#39;backbone.conv7.weight&#39;</span><span class="p">:</span> <span class="mf">0.8500000000000002</span><span class="p">,</span> <span class="s1">&#39;classifier.weight&#39;</span><span class="p">:</span> <span class="mf">0.9500000000000003</span><span class="p">}</span>
<span class="n">Pruning</span> <span class="n">Time</span> <span class="n">Consumed</span> <span class="p">(</span><span class="n">secs</span><span class="p">):</span> <span class="mf">1701416101.321775</span>
<span class="n">Total</span> <span class="n">Pruning</span> <span class="n">Time</span> <span class="n">Consumed</span> <span class="p">(</span><span class="n">mins</span><span class="p">):</span> <span class="mf">2.8907041509946185</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Pruned</span> <span class="n">Model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">9.94</span> <span class="n">MiB</span><span class="p">(</span><span class="n">non</span><span class="o">-</span><span class="n">zeros</span><span class="p">)</span> <span class="o">=</span> <span class="mf">28.22</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="o">.................</span> <span class="n">Comparison</span> <span class="n">Table</span>  <span class="o">.................</span>
                <span class="n">Original</span>        <span class="n">Pruned</span>          <span class="n">Reduction</span> <span class="n">Ratio</span>
<span class="n">Latency</span> <span class="p">(</span><span class="n">ms</span><span class="p">)</span>    <span class="mf">5.9</span>             <span class="mf">5.8</span>             <span class="mf">1.0</span>
<span class="n">MACs</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>        <span class="mi">606</span>             <span class="mi">606</span>             <span class="mf">1.0</span>
<span class="n">Param</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>       <span class="mf">9.23</span>            <span class="mf">2.6</span>             <span class="mf">3.5</span>
<span class="n">Accuracies</span> <span class="p">(</span><span class="o">%</span><span class="p">)</span>  <span class="mf">93.136</span>          <span class="mf">87.735</span>          <span class="o">-</span><span class="mf">5.401</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Sparse</span> <span class="n">model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">9.94</span> <span class="n">MiB</span> <span class="o">=</span> <span class="mf">28.22</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Pruned</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">87.73547094188376</span>
</pre></div>
</div>
</section>
</section>
<section id="spiking-neural-network-compression">
<h1>Spiking Neural Network Compression<a class="headerlink" href="#spiking-neural-network-compression" title="Link to this heading"></a></h1>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pip install snntorch -q
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Import snntorch libraries
import snntorch as snn
from snntorch import surrogate
from snntorch import backprop
from snntorch import functional as SF
from snntorch import utils
from snntorch import spikeplot as splt
from torch import optim

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import torch.nn.functional as F

import matplotlib.pyplot as plt
import numpy as np
import itertools
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="n">b898cb6c07c2</span><span class="o">&gt;</span><span class="p">:</span><span class="mi">4</span><span class="p">:</span> <span class="ne">DeprecationWarning</span><span class="p">:</span> <span class="n">The</span> <span class="n">module</span> <span class="n">snntorch</span><span class="o">.</span><span class="n">backprop</span> <span class="n">will</span> <span class="n">be</span> <span class="n">deprecated</span> <span class="ow">in</span>  <span class="n">a</span> <span class="n">future</span> <span class="n">release</span><span class="o">.</span> <span class="n">Writing</span> <span class="n">out</span> <span class="n">your</span> <span class="n">own</span> <span class="n">training</span> <span class="n">loop</span> <span class="n">will</span> <span class="n">lead</span> <span class="n">to</span> <span class="n">substantially</span> <span class="n">faster</span> <span class="n">performance</span><span class="o">.</span>
  <span class="kn">from</span> <span class="nn">snntorch</span> <span class="kn">import</span> <span class="n">backprop</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Event Drive Data

# dataloader arguments
batch_size = 128
data_path = &quot;./data/mnist&quot;

dtype = torch.float
device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)

# Define a transform
transform = transforms.Compose(
    [
        transforms.Resize((28, 28)),
        transforms.Grayscale(),
        transforms.ToTensor(),
        transforms.Normalize((0,), (1,)),
    ]
)

mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)
mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)

# Create DataLoaders
train_loader = DataLoader(
    mnist_train, batch_size=batch_size, shuffle=True, drop_last=True
)
test_loader = DataLoader(
    mnist_test, batch_size=batch_size, shuffle=True, drop_last=True
)
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sconce import sconce
sconces = sconce()
# Set you Dataloader
dataloader = {}
dataloader[&quot;train&quot;] = train_loader
dataloader[&quot;test&quot;] = test_loader
sconces.dataloader = dataloader
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#Enable snn in sconce
sconces.snn = True

# Load your snn Model
spike_grad = surrogate.fast_sigmoid(slope=25)
beta = 0.5
snn_model = nn.Sequential(
    nn.Conv2d(1, 12, 5),
    nn.MaxPool2d(2),
    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),
    nn.Conv2d(12, 64, 5),
    nn.MaxPool2d(2),
    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),
    nn.Flatten(),
    nn.Linear(64 * 4 * 4, 10),
    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True),
).to(&#39;cuda&#39;)


#Load the pretrained weights
snn_pretrained_model_path = &quot;drive/MyDrive/Efficientml/Efficientml.ai/snn_model.pth&quot;
snn_model.load_state_dict(torch.load(snn_pretrained_model_path))  # Model Definition
sconces.model = snn_model
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sconces.optimizer = optim.Adam(sconces.model.parameters(), lr=1e-4)
sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)

sconces.criterion = SF.ce_rate_loss()

sconces.epochs = 10  # Number of time we iterate over the data
sconces.device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
sconces.experiment_name = &quot;snn-gmp&quot;  # Define your experiment name here
sconces.prune_mode = &quot;GMP&quot;
sconces.num_finetune_epochs = 1
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sconces.compress()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Dense</span> <span class="n">Model</span> <span class="n">Size</span> <span class="n">Model</span><span class="o">=</span><span class="mf">0.11</span> <span class="n">MiB</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">97.11538461538461</span> <span class="o">%</span>
<span class="n">Granular</span><span class="o">-</span><span class="n">Magnitude</span> <span class="n">Pruning</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sparsity</span> <span class="k">for</span> <span class="n">each</span> <span class="n">Layer</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;0.weight&#39;</span><span class="p">:</span> <span class="mf">0.6500000000000001</span><span class="p">,</span> <span class="s1">&#39;3.weight&#39;</span><span class="p">:</span> <span class="mf">0.5000000000000001</span><span class="p">,</span> <span class="s1">&#39;7.weight&#39;</span><span class="p">:</span> <span class="mf">0.7000000000000002</span><span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Pruned</span> <span class="n">Model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">0.05</span> <span class="n">MiB</span><span class="p">(</span><span class="n">non</span><span class="o">-</span><span class="n">zeros</span><span class="p">)</span> <span class="o">=</span> <span class="mf">43.13</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">1</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">95.97356</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="o">.................</span> <span class="n">Comparison</span> <span class="n">Table</span>  <span class="o">.................</span>
                <span class="n">Original</span>        <span class="n">Pruned</span>          <span class="n">Reduction</span> <span class="n">Ratio</span>
<span class="n">Latency</span> <span class="p">(</span><span class="n">ms</span><span class="p">)</span>    <span class="mf">2.09</span>            <span class="mf">1.43</span>            <span class="mf">1.5</span>
<span class="n">MACs</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>        <span class="mi">160</span>             <span class="mi">160</span>             <span class="mf">1.0</span>
<span class="n">Param</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>       <span class="mf">0.01</span>            <span class="mf">0.01</span>            <span class="mf">1.0</span>
<span class="n">Accuracies</span> <span class="p">(</span><span class="o">%</span><span class="p">)</span>  <span class="mf">97.115</span>          <span class="mf">95.974</span>          <span class="o">-</span><span class="mf">1.142</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Sparse</span> <span class="n">model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">0.05</span> <span class="n">MiB</span> <span class="o">=</span> <span class="mf">43.13</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Pruned</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">95.9735576923077</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torchprofile</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">22</span><span class="p">:</span> <span class="ne">UserWarning</span><span class="p">:</span> <span class="n">No</span> <span class="n">handlers</span> <span class="n">found</span><span class="p">:</span> <span class="s2">&quot;prim::pythonop&quot;</span><span class="o">.</span> <span class="n">Skipped</span><span class="o">.</span>
  <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No handlers found: &quot;</span><span class="si">{}</span><span class="s1">&quot;. Skipped.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torchprofile</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">22</span><span class="p">:</span> <span class="ne">UserWarning</span><span class="p">:</span> <span class="n">No</span> <span class="n">handlers</span> <span class="n">found</span><span class="p">:</span> <span class="s2">&quot;prim::pythonop&quot;</span><span class="o">.</span> <span class="n">Skipped</span><span class="o">.</span>
  <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No handlers found: &quot;</span><span class="si">{}</span><span class="s1">&quot;. Skipped.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</pre></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Pruning.html" class="btn btn-neutral float-right" title="Pruning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Sathyaprakash.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>