<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sconce Pipeline Tutorial &mdash; sconce 0.57 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/default.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2fd344d2"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Quantization" href="Quantization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            sconce
              <img src="../_static/sconce-punch-bk_removed.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.57.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Pruning.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Quantization.html">Quantization</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">sconce Pipeline Tutorial</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sconce</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">sconce Pipeline Tutorial</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/Pipeline-Tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sconce-pipeline-tutorial">
<h1>sconce Pipeline Tutorial<a class="headerlink" href="#sconce-pipeline-tutorial" title="Link to this heading">ïƒ</a></h1>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install sconce -q


<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">OrderedDict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span> \
<span class="s2">&quot;The current runtime does not have CUDA support.&quot;</span> \
<span class="s2">&quot;Please go to menu bar (Runtime - Change runtime type) and select GPU&quot;</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m153.1/153.1 kB[0m [31m2.7 MB/s[0m eta [36m0:00:00[0m
[?25h  Installing build dependencies ... [?25l[?25hdone
  Getting requirements to build wheel ... [?25l[?25hdone
  Installing backend dependencies ... [?25l[?25hdone
  Preparing metadata (pyproject.toml) ... [?25l[?25hdone
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m11.6/11.6 MB[0m [31m107.4 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m18.2/18.2 MB[0m [31m64.4 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m3.6/3.6 MB[0m [31m76.9 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m109.0/109.0 kB[0m [31m14.1 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m7.9/7.9 MB[0m [31m124.0 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m302.0/302.0 kB[0m [31m39.0 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m3.8/3.8 MB[0m [31m117.8 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.3/1.3 MB[0m [31m89.1 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m53.1/53.1 kB[0m [31m7.6 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.6/1.6 MB[0m [31m86.4 MB/s[0m eta [36m0:00:00[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m295.0/295.0 kB[0m [31m35.5 MB/s[0m eta [36m0:00:00[0m
[?25h  Building wheel for lit (pyproject.toml) ... [?25l[?25hdone
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
lida 0.0.10 requires fastapi, which is not installed.
lida 0.0.10 requires kaleido, which is not installed.
lida 0.0.10 requires python-multipart, which is not installed.
lida 0.0.10 requires uvicorn, which is not installed.
cupy-cuda11x 11.0.0 requires numpy&lt;1.26,&gt;=1.20, but you have numpy 1.26.1 which is incompatible.
imageio 2.31.6 requires pillow&lt;10.1.0,&gt;=8.3.2, but you have pillow 10.1.0 which is incompatible.
numba 0.56.4 requires numpy&lt;1.24,&gt;=1.18, but you have numpy 1.26.1 which is incompatible.
tensorflow-probability 0.22.0 requires typing-extensions&lt;4.6.0, but you have typing-extensions 4.8.0 which is incompatible.[0m[31m
[0mName: sconce
Version: 0.57
Summary: sconce: torch pipeliner
Home-page: https://github.com/satabios/sconce
Author: Sathyaprakash Narayanan
Author-email: Sathyaprakash Narayanan &lt;snaray17@ucsc.edu&gt;
License:
Location: /usr/local/lib/python3.10/dist-packages
Requires: certifi, charset-normalizer, cmake, contourpy, cycler, fast-pytorch-kmeans, filelock, fonttools, idna, ipdb, Jinja2, kiwisolver, lit, MarkupSafe, matplotlib, mpmath, networkx, numpy, packaging, Pillow, pyparsing, python-dateutil, requests, six, snntorch, sympy, torch, torchprofile, torchvision, tqdm, transformers, typing-extensions, urllib3
Required-by:
</pre></div>
</div>
<p>Load the Pre-Trained Model Weights</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;drive/MyDrive/Efficientml/Efficientml.ai/pre-trained_vgg.cifar.pretrained.pth&quot;</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Drive</span> <span class="n">already</span> <span class="n">mounted</span> <span class="n">at</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">drive</span><span class="p">;</span> <span class="n">to</span> <span class="n">attempt</span> <span class="n">to</span> <span class="n">forcibly</span> <span class="n">remount</span><span class="p">,</span> <span class="n">call</span> <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">,</span> <span class="n">force_remount</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="n">ARCH</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">counts</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">layer</span><span class="p">))</span>
      <span class="n">counts</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ARCH</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span>
        <span class="c1"># conv-bn-relu</span>
        <span class="n">add</span><span class="p">(</span><span class="s2">&quot;conv&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="n">add</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">add</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">x</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># maxpool</span>
        <span class="n">add</span><span class="p">(</span><span class="s2">&quot;pool&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">(</span><span class="n">layers</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="c1"># backbone: [N, 3, 32, 32] =&gt; [N, 512, 2, 2]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># avgpool: [N, 512, 2, 2] =&gt; [N, 512]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># classifier: [N, 512] =&gt; [N, 10]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="c1">#load the pretrained model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">VGG</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;state_dict&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">All</span> <span class="n">keys</span> <span class="n">matched</span> <span class="n">successfully</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Setup the Dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">RandomCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
        <span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">ToTensor</span><span class="p">(),</span>
    <span class="p">]),</span>
    <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">}</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]:</span>

    <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data/cifar10&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
    <span class="p">)</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]:</span>
  <span class="n">dataloader</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Downloading</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">cs</span><span class="o">.</span><span class="n">toronto</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">kriz</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span> <span class="n">to</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:12&lt;00:00, 13129669.34it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Extracting</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span><span class="o">/</span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span> <span class="n">to</span> <span class="n">data</span><span class="o">/</span><span class="n">cifar10</span>
<span class="n">Files</span> <span class="n">already</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span>
</pre></div>
</div>
<p>sconce Configurations</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sconce</span> <span class="kn">import</span> <span class="n">sconce</span>


<span class="n">sconces</span> <span class="o">=</span> <span class="n">sconce</span><span class="p">()</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">=</span> <span class="n">model</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> <span class="c1"># Loss</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">sconces</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1">#Number of time we iterate over the data</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;vgg-gmp&quot;</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">prune_mode</span> <span class="o">=</span> <span class="s2">&quot;GMP&quot;</span> <span class="c1"># Supports Automated Pruning Ratio Detection</span>
</pre></div>
</div>
<p>Train and Validated the Model on the given dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="c1"># Evaludate the model</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>train:   0%|          | 0/98 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">1</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">92.89579</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">92.89579158316633</span>
</pre></div>
</div>
<p>Magic Happens here: Compress the model(GMP pruning is set as the prune
mode[sconces.prune_mode] above)</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compress the model</span>
<span class="n">sconces</span><span class="o">.</span><span class="n">compress</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Dense_model_size</span> <span class="n">model</span> <span class="n">after</span> <span class="n">sensitivity</span> <span class="n">size</span><span class="o">=</span><span class="mf">35.20</span> <span class="n">MiB</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">92.89579158316633</span> <span class="o">%</span>
<span class="n">Granular</span><span class="o">-</span><span class="n">Magnitude</span> <span class="n">Pruning</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Sparsity for each Layer: {&#39;backbone.conv0.weight&#39;: 0.20000000000000004, &#39;backbone.conv1.weight&#39;: 0.30000000000000004, &#39;backbone.conv2.weight&#39;: 0.1, &#39;backbone.conv3.weight&#39;: 0.3500000000000001, &#39;backbone.conv4.weight&#39;: 0.3500000000000001, &#39;backbone.conv5.weight&#39;: 0.3500000000000001, &#39;backbone.conv6.weight&#39;: 0.3500000000000001, &#39;backbone.conv7.weight&#39;: 0.3500000000000001, &#39;classifier.weight&#39;: 0.6500000000000001}
Pruned model has size=23.18 MiB = 65.85% of Original model size

train:   0%|          | 0/98 [00:00&lt;?, ?it/s]

test:   0%|          | 0/20 [00:00&lt;?, ?it/s]

Epoch:1 Train Loss: 0.00000 Validation Accuracy: 93.27655
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>train:   0%|          | 0/98 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">2</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.13627</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>train:   0%|          | 0/98 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">3</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.22645</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>train:   0%|          | 0/98 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">4</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.16633</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>train:   0%|          | 0/98 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span><span class="p">:</span><span class="mi">5</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.00000</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.19639</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>test:   0%|          | 0/20 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                <span class="n">Original</span>        <span class="n">Pruned</span>          <span class="n">Reduction</span> <span class="n">Ratio</span>
<span class="n">Latency</span> <span class="p">(</span><span class="n">ms</span><span class="p">)</span>    <span class="mf">19900.0</span>         <span class="mf">19900.0</span>         <span class="mf">1.0</span>
<span class="n">MACs</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>        <span class="mi">606</span>             <span class="mi">606</span>             <span class="mf">1.0</span>
<span class="n">Param</span> <span class="p">(</span><span class="n">M</span><span class="p">)</span>       <span class="mf">9.23</span>            <span class="mf">9.23</span>            <span class="mf">1.0</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Sparse</span> <span class="n">model</span> <span class="n">has</span> <span class="n">size</span><span class="o">=</span><span class="mf">23.18</span> <span class="n">MiB</span> <span class="o">=</span> <span class="mf">65.85</span><span class="o">%</span> <span class="n">of</span> <span class="n">Original</span> <span class="n">model</span> <span class="n">size</span>
<span class="n">Fine</span><span class="o">-</span><span class="n">Tuned</span> <span class="n">Pruned</span> <span class="n">Model</span> <span class="n">Validation</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">93.19639278557115</span>
</pre></div>
</div>
<p>Notice that intially,</p>
<ul class="simple">
<li><p><strong>Dense Model</strong> has a size of <em>35.20MiB</em> and accuracy of <em>92.89%</em>.</p></li>
<li><p><strong>Post Pruning(GMP) Pruned Model</strong> size <em>23.18MiB</em> with accuracy of
<em>65.85%</em>.</p></li>
<li><p>Upon <strong>fine-tuning the Prune Model</strong>, we have the final pruned model
size of <em>23.18MiB</em> with an accuracy of <em>93.19%</em>.</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Original</p></th>
<th class="head"><p>Pruned</p></th>
<th class="head"><p>Reduction Ratio</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Latency (ms)</p></td>
<td><p>19900.0</p></td>
<td><p>19900.0</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>MACs (M)</p></td>
<td><p>606</p></td>
<td><p>606</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-even"><td><p>Param (M)</p></td>
<td><p>9.23</p></td>
<td><p>9.23</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>Fine-Tuned Sparse
Model Size</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>23.18 MiB</p></td>
<td><p>65.85%</p></td>
</tr>
<tr class="row-even"><td><p>Fine-Tuned Pruned
Model Validation
Accuracy</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>93.196%</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
</tr>
</tbody>
</table>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Quantization.html" class="btn btn-neutral float-left" title="Quantization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Sathyaprakash.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>