{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sathya/anaconda3/envs/zen/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "transforms = {\n",
    "    \"train\":  transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "    \"test\":  transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = datasets.MNIST(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms.get(split),\n",
    "  )\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=512,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1) \n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Train Loss: 0.00000 Validation Accuracy: 92.24449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 Train Loss: 0.00000 Validation Accuracy: 92.28457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 Train Loss: 0.00000 Validation Accuracy: 92.19439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 Train Loss: 0.00000 Validation Accuracy: 92.54509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 Train Loss: 0.00000 Validation Accuracy: 92.96593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 Train Loss: 0.00000 Validation Accuracy: 92.99599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7 Train Loss: 0.00000 Validation Accuracy: 93.05611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 Train Loss: 0.00000 Validation Accuracy: 93.50701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 Train Loss: 0.00000 Validation Accuracy: 93.60721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 Train Loss: 0.00000 Validation Accuracy: 93.82766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from sconce import sconce\n",
    "\n",
    "sconces = sconce()\n",
    "sconces.model= Net() # Model Definition\n",
    "sconces.criterion = nn.CrossEntropyLoss() # Loss\n",
    "sconces.optimizer= optim.Adam(sconces.model.parameters(), lr=1e-4)\n",
    "sconces.scheduler = optim.lr_scheduler.CosineAnnealingLR(sconces.optimizer, T_max=200)\n",
    "sconces.dataloader = dataloader\n",
    "sconces.epochs = 10 #Number of time we iterate over the data\n",
    "sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sconces.experiment_name = \"ptq\" # Define your experiment name here\n",
    "    \n",
    "   \n",
    "sconces.train()\n",
    "sconces.epochs = 10 #Number of time we iterate over the data\n",
    "sconces.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sconces.experiment_name = \"ptq\" # Define your experiment name here\n",
    "    \n",
    "   \n",
    "sconces.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'ptq.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.82765531062124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sconces.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 0.0155,  0.0052,  0.0159,  ...,  0.0197,  0.0095, -0.0005],\n",
      "        [-0.0068,  0.0042, -0.0486,  ...,  0.0128, -0.0346, -0.0415],\n",
      "        [-0.0371,  0.0240, -0.0176,  ..., -0.0015, -0.0090, -0.0394],\n",
      "        ...,\n",
      "        [-0.0173, -0.0132,  0.0111,  ..., -0.0179, -0.0355,  0.0213],\n",
      "        [ 0.0144, -0.0423, -0.0032,  ..., -0.0063, -0.0037, -0.0377],\n",
      "        [ 0.0240, -0.0030,  0.0295,  ...,  0.0229,  0.0326, -0.0246]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print('Weights before quantization')\n",
    "print(sconces.model.linear1.weight)\n",
    "print(sconces.model.linear1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 361.062\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(sconces.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.82765531062124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Accuracy of the model before quantization: ')\n",
    "sconces.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert min-max observers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(QuantizedNet,self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1) \n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedNet(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "net_quantized = QuantizedNet().to(device)\n",
    "# Copy weights from unquantized model\n",
    "net_quantized.load_state_dict(torch.load('ptq.pth'))\n",
    "net_quantized.eval()\n",
    "sconces.model = net_quantized\n",
    "\n",
    "net_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
    "sconces.model = torch.ao.quantization.prepare(sconces.model) # Insert observers\n",
    "sconces.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.82765531062124"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sconces.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedNet(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.0)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-6.078974723815918, max_val=5.0761823654174805)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-2.7763729095458984, max_val=4.160463809967041)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-3.7380480766296387, max_val=3.566555976867676)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check statistics of the various layers')\n",
    "sconces.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize the model using the statistics collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sconces.model = torch.ao.quantization.convert(sconces.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedNet(\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.0878358855843544, zero_point=69, qscheme=torch.per_tensor_affine)\n",
       "  (linear2): QuantizedLinear(in_features=100, out_features=100, scale=0.054620761424303055, zero_point=51, qscheme=torch.per_tensor_affine)\n",
       "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.057516567409038544, zero_point=65, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check statistics of the various layers')\n",
    "sconces.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights of the model after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[ 14,   5,  15,  ...,  18,   9,   0],\n",
      "        [ -6,   4, -45,  ...,  12, -32, -38],\n",
      "        [-34,  22, -16,  ...,  -1,  -8, -36],\n",
      "        ...,\n",
      "        [-16, -12,  10,  ..., -17, -33,  20],\n",
      "        [ 13, -39,  -3,  ...,  -6,  -3, -35],\n",
      "        [ 22,  -3,  27,  ...,  21,  30, -23]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model after quantization\n",
    "print('Weights after quantization')\n",
    "print(torch.int_repr(sconces.model.linear1.weight()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the dequantized weights and the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0221,  0.0258, -0.0088,  ..., -0.0141,  0.0051, -0.0318],\n",
      "        [-0.0217, -0.0136,  0.0185,  ..., -0.0012, -0.0012, -0.0017],\n",
      "        [ 0.0142,  0.0089, -0.0053,  ...,  0.0311, -0.0181,  0.0020]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[ 0.0151,  0.0054,  0.0162,  ...,  0.0195,  0.0097,  0.0000],\n",
      "        [-0.0065,  0.0043, -0.0487,  ...,  0.0130, -0.0346, -0.0411],\n",
      "        [-0.0368,  0.0238, -0.0173,  ..., -0.0011, -0.0086, -0.0389],\n",
      "        ...,\n",
      "        [-0.0173, -0.0130,  0.0108,  ..., -0.0184, -0.0357,  0.0216],\n",
      "        [ 0.0141, -0.0422, -0.0032,  ..., -0.0065, -0.0032, -0.0378],\n",
      "        [ 0.0238, -0.0032,  0.0292,  ...,  0.0227,  0.0324, -0.0249]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(net.linear1.weight)\n",
    "print('')\n",
    "print(f'Dequantized weights: ')\n",
    "print(torch.dequantize(sconces.model.linear1.weight()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print size and accuracy of the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model after quantization\n",
      "Size (KB): 95.394\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model after quantization')\n",
    "print_size_of_model(sconces.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.937875751503"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing the model after quantization')\n",
    "sconces.model.to('cpu')\n",
    "sconces.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
